{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Face Encodings:\n",
      "axar_patel: [-0.12392433  0.00884983  0.03801131 -0.0680173   0.00418645 -0.10794856\n",
      "  0.00529506 -0.11123012  0.132594   -0.10374687]...\n",
      "hardik_pandya: [-0.21928403  0.08495818  0.11501925  0.02033386 -0.10233393  0.00678758\n",
      "  0.05167035 -0.05003983  0.15901046  0.0560272 ]...\n",
      "rohit_sharma: [-0.18914437  0.11694089  0.02240411 -0.06889097 -0.00819308 -0.01212921\n",
      "  0.02242361 -0.0260885   0.17662366 -0.00845366]...\n",
      "arshdeep_singh: [-0.14878276  0.07868053  0.03937501 -0.00706431 -0.0212716  -0.0419291\n",
      " -0.02700392 -0.07469609  0.15457048 -0.01123893]...\n",
      "shubhman_gill: [-0.23507263  0.1061626   0.03380397 -0.07815167 -0.08625772  0.00963422\n",
      " -0.06139155 -0.05667412  0.16558984 -0.07973208]...\n",
      "dawlat_zadran: [-0.1316476  -0.0002081   0.04108113 -0.02778954 -0.06500793 -0.06418108\n",
      "  0.02324793  0.00399723  0.15321727 -0.0113908 ]...\n",
      "travis_head: [-0.10859749  0.08510618  0.03607509 -0.05483475 -0.10359889  0.041487\n",
      " -0.06288593 -0.07826832  0.0268977  -0.02615542]...\n",
      "chahal_yuzvendra: [-0.1643713   0.06701053  0.10892949 -0.05380002  0.06222296 -0.01678315\n",
      " -0.01643083 -0.04134109  0.14867051 -0.05229008]...\n",
      "anrich_nortje: [-0.07281623  0.11759073  0.05807383  0.03806263 -0.05481234  0.07385507\n",
      "  0.01877527 -0.13680607  0.2039921  -0.05410464]...\n",
      "ravichandran_ashwin: [-0.09889984  0.03755146  0.05262509 -0.08501564 -0.02368395  0.02380441\n",
      "  0.02691001 -0.08309231  0.19811924 -0.02854336]...\n",
      "aaron_finch: [-0.21735185  0.11429388  0.01564839 -0.02436349 -0.12117399 -0.04486972\n",
      " -0.02381818 -0.14844003  0.09411028 -0.00077166]...\n",
      "ab_de_villiers: [-0.11320381  0.08386783  0.03249545 -0.04575469 -0.03658158  0.04531613\n",
      "  0.02898996 -0.04733881  0.12862854  0.03036565]...\n",
      "chris_jordan: [-0.15247083  0.08318982  0.1575377   0.04085277 -0.03456245 -0.06308531\n",
      "  0.00960783 -0.06800342  0.17648794 -0.01538595]...\n",
      "marnus_labuschagne: [-0.0716765   0.05941489  0.09232406 -0.053713   -0.13918294  0.06482799\n",
      " -0.09901536 -0.13459221  0.04080422 -0.10709845]...\n",
      "glenn_maxwell: [-0.13287097  0.10476194  0.04672771 -0.08413097 -0.07895113  0.06015262\n",
      " -0.02352702 -0.08825599  0.18555352  0.03243892]...\n",
      "quinton_de_kock: [-0.12514648  0.06092932  0.04746813 -0.03659844 -0.03418782  0.01161618\n",
      " -0.06247274 -0.06961364  0.13484034 -0.11941414]...\n",
      "aiden_markram: [-0.22583547  0.08204711  0.00179078 -0.05235783 -0.07413539 -0.10572607\n",
      " -0.0060583  -0.07059408  0.16122212 -0.01411728]...\n",
      "moeen_ali: [-0.07261263 -0.03772039  0.05335173 -0.04656814 -0.05792189 -0.02033972\n",
      "  0.09048863  0.01452053  0.16857466 -0.00943865]...\n",
      "ajinkya_rahane: [-0.08311763  0.07939954  0.04094374 -0.09844749 -0.03418245 -0.10926419\n",
      " -0.03758194  0.00026823  0.13788009 -0.0064675 ]...\n",
      "shapoor_zadran: [-0.15245929  0.05420148  0.02890711 -0.0502317  -0.06341434 -0.00258155\n",
      " -0.01614366 -0.0575029   0.24225143 -0.06572686]...\n",
      "daryl_mitchell: [-0.1501652   0.05221681  0.00547558 -0.04747579 -0.07694691 -0.00684999\n",
      " -0.09956853 -0.00173331  0.14463349 -0.02344164]...\n",
      "tom_blundell: [-0.07598356  0.08730431  0.05351557 -0.06873178 -0.09199961  0.03703792\n",
      "  0.02902618  0.05259174  0.19986899 -0.10413685]...\n",
      "ravindra_jadeja: [-0.12613331  0.11468676  0.05488857  0.00346489 -0.12055704 -0.0365317\n",
      " -0.04521462 -0.03353744  0.14131144 -0.05024768]...\n",
      "chris_woakes: [-0.13098939  0.09027171  0.114012   -0.07039899 -0.12090975  0.07260353\n",
      " -0.11753038 -0.00999258  0.19771522 -0.07742665]...\n",
      "ms_dhoni: [-0.09030505  0.16148672  0.05349178 -0.03233052 -0.10453588 -0.01657688\n",
      " -0.11120091 -0.10157195  0.16135032 -0.04770916]...\n",
      "joe_root: [-0.19123529  0.12873837  0.06021309 -0.14771532 -0.16808943  0.02294144\n",
      " -0.04521377 -0.09367964  0.15519767 -0.11178894]...\n",
      "devon_conway: [-0.13025351  0.05938664  0.12175546 -0.08814947 -0.20461902  0.0773406\n",
      " -0.00246096 -0.03711494  0.1170058  -0.07047393]...\n",
      "patrick_cummins: [-0.03467812  0.10709662  0.05477171 -0.03391017 -0.16861901  0.05079255\n",
      " -0.02798777 -0.02534582  0.12776735 -0.04124276]...\n",
      "liam_livingstone: [-0.17616586  0.13339898  0.08664231 -0.08629533 -0.13053302  0.05184199\n",
      " -0.03250622  0.02607157  0.11020874 -0.04873704]...\n",
      "ish_sodhi: [-0.15567969  0.11036533  0.11907236 -0.01854808 -0.11811257  0.00967199\n",
      " -0.02830487  0.00780907  0.17514108 -0.0066163 ]...\n",
      "ashton_agar: [-0.06446332  0.13345712  0.07538215 -0.02782919 -0.12364366  0.12756687\n",
      " -0.01373918  0.01749304  0.19933644 -0.07385132]...\n",
      "virat_kohli: [-0.11251982  0.08296992  0.05818208  0.01461596 -0.04671844 -0.02780107\n",
      "  0.00714785 -0.02462002  0.16904236 -0.03102734]...\n",
      "heinrich_klaasen: [-0.07869732  0.14846309 -0.05643237 -0.11186107 -0.20126605  0.05374289\n",
      "  0.02096928 -0.14397043  0.10083404 -0.04357519]...\n",
      "james_anderson: [-0.1395137   0.14053293 -0.02934847 -0.07614595 -0.04512269 -0.09230435\n",
      " -0.01700203 -0.11484297  0.08187463  0.0365229 ]...\n",
      "jake_fraser-mcgurk: [-0.06675271  0.06117943  0.03428041 -0.07144853 -0.11207382  0.0068458\n",
      "  0.0342925  -0.08778128  0.0673294  -0.05777109]...\n",
      "ben_stokes: [-0.13714038  0.10253198  0.04362992 -0.08520886 -0.13101925  0.05662794\n",
      "  0.03727042 -0.037539    0.08517511 -0.12965484]...\n",
      "adam_zampa: [-0.10643361  0.04487527  0.00208964 -0.12389534 -0.11446911 -0.01786147\n",
      " -0.01076037 -0.11856332  0.16099383 -0.1667978 ]...\n",
      "yuvraj_singh: [-0.2081124   0.11507609 -0.0066595  -0.00472624 -0.08054101  0.05275428\n",
      "  0.05439673  0.00714939  0.1575972   0.00208073]...\n",
      "bhuvneshwar_kumar: [-0.15833911  0.04186033  0.12303367 -0.05537515 -0.11477396 -0.0262302\n",
      " -0.03760722  0.03671085  0.16693681 -0.0750998 ]...\n",
      "gus_atkinson: [-0.15953061  0.10480893  0.01040337 -0.10986862 -0.14260343 -0.00552846\n",
      " -0.03478176 -0.06755236  0.16941652 -0.10766327]...\n",
      "ajaz_patel: [-0.13921411  0.08902317  0.13383272 -0.09170122 -0.04948047 -0.06831357\n",
      " -0.02047597 -0.04696579  0.13518758 -0.02336556]...\n",
      "marcus_stoinis: [-0.04958899  0.08644932  0.07029533 -0.05636308 -0.13071647  0.02821391\n",
      " -0.1167493  -0.0898641   0.19034941 -0.09967098]...\n",
      "sam_curran: [-0.1203559   0.10833848 -0.04105758 -0.09152402 -0.15560509 -0.01345524\n",
      "  0.04826859 -0.04751393  0.15276147 -0.00713778]...\n",
      "lockie_ferguson: [-0.05862816  0.11782581  0.02441144 -0.08938567 -0.15469055 -0.01860905\n",
      " -0.03978603 -0.02325823  0.07854611 -0.04885583]...\n",
      "harry_brook: [-0.15932634  0.07134816  0.04434931  0.0184093  -0.15194796  0.05213055\n",
      "  0.03788989 -0.11409488  0.12547834 -0.08972263]...\n",
      "hamid_hassan: [-0.12165166  0.1214852   0.00849696 -0.06729472 -0.09526111  0.0165068\n",
      "  0.00520648 -0.00255499  0.13556331 -0.01751468]...\n",
      "josh_hazlewood: [-0.10039753  0.05438897 -0.00348157 -0.08555987 -0.17012069 -0.01272623\n",
      "  0.01501577 -0.10994789  0.08684699 -0.04971349]...\n",
      "mitchell_starc: [-0.03445007  0.17351355  0.03042831 -0.11811826 -0.20284678 -0.028405\n",
      " -0.13430946 -0.04521148  0.07944375 -0.04989208]...\n",
      "kane_williamson: [-0.15699428  0.12251129  0.06146185 -0.15495889 -0.15175675  0.09014808\n",
      " -0.04138148  0.03241891  0.07995614 -0.0633943 ]...\n",
      "ruturaj_gaikwad: [-0.20778827  0.01236068  0.01381018  0.011915   -0.05414465 -0.01918106\n",
      " -0.01980275 -0.04510491  0.15014288 -0.0173985 ]...\n",
      "rashid_khan: [-0.13848531  0.07280224  0.06674272 -0.01426519 -0.02472105 -0.04612366\n",
      "  0.00906698 -0.04556663  0.17569987 -0.02486118]...\n",
      "jonny_bairstow: [-0.09151693  0.08911229  0.05651809 -0.08098499 -0.08021806  0.0304386\n",
      " -0.03592664 -0.0102606   0.17596948 -0.05606871]...\n",
      "harbhajan_singh: [-0.24568519  0.0838437   0.02956793 -0.06538165 -0.09107814  0.00665405\n",
      " -0.02306673 -0.00900734  0.15264854 -0.1102221 ]...\n",
      "martin_guptill: [-0.16381653  0.08667537  0.05328942 -0.04884785 -0.25289622 -0.01373618\n",
      " -0.03354051 -0.11053692  0.07970847 -0.04029509]...\n",
      "tim_southee: [-0.12607208  0.16797277  0.03291268 -0.06376746 -0.15859023  0.0164271\n",
      " -0.14391808  0.02298336  0.13390014  0.02629426]...\n",
      "keshav_maharaj: [-0.21338442 -0.0130395  -0.00423093 -0.08037598 -0.10325705  0.01156514\n",
      " -0.01434926  0.00857511  0.1425402  -0.02951033]...\n",
      "mohammad_nabi: [-0.1418706   0.01017698  0.02247083 -0.03178551 -0.09078332 -0.01445764\n",
      "  0.0284046  -0.05982724  0.21457826 -0.11936393]...\n",
      "andile_phehlukwayo: [-0.18504938  0.14061077  0.11861664 -0.0250294  -0.07857169 -0.12431498\n",
      "  0.03487745 -0.10547847  0.12037804 -0.01320326]...\n",
      "marco_jansen: [-0.18502066  0.08158027 -0.00786433 -0.0568235  -0.13745277  0.0081788\n",
      " -0.03309121 -0.05631286  0.15801403  0.04630449]...\n",
      "mohammed_shami: [-0.16035865  0.1596808   0.0944228  -0.02632656 -0.14217126 -0.02963154\n",
      " -0.10081516 -0.03967031  0.13953441 -0.01571234]...\n",
      "rishabh_pant: [-0.15335166  0.07830308  0.02501362 -0.05924763 -0.12975648 -0.02052192\n",
      " -0.06501371 -0.06332487  0.10376463 -0.01415052]...\n",
      "yashasvi_jaiswal: [-0.14610292  0.13777927  0.01274548 -0.01363985 -0.06924482 -0.07231916\n",
      " -0.00762325 -0.11270773  0.21237485 -0.05592746]...\n",
      "aaron_hardie: [-0.19372673  0.07554425 -0.00706969 -0.11917518 -0.07016265 -0.08942836\n",
      "  0.05313003 -0.02964631  0.15953626 -0.01324785]...\n",
      "james_neesham: [-0.12431557  0.20230211  0.0843543  -0.08307031 -0.17886405  0.05608135\n",
      " -0.0480825  -0.07089228  0.06718443 -0.06539776]...\n",
      "samiullah_shinwari: [-0.12922153  0.11343959 -0.00667736 -0.04204736 -0.08822124 -0.02719893\n",
      "  0.05220891 -0.03592478  0.11173528  0.04224454]...\n",
      "virender_sehwag: [-0.1571596   0.04899274  0.03240826 -0.05154641 -0.09455279 -0.00247043\n",
      "  0.00123669 -0.12197438  0.11937068 -0.06177612]...\n",
      "dale_steyn: [-0.14484292  0.16782875 -0.06650191 -0.04939682 -0.1107416   0.0151735\n",
      " -0.08555486 -0.15008274  0.15376994  0.04167698]...\n",
      "matthew_wade: [ 0.0391277   0.12277313  0.02139855 -0.07433106 -0.20682244  0.05437857\n",
      "  0.02925568 -0.0393226   0.17583141 -0.07252694]...\n",
      "kl_rahul: [-0.1003551   0.07701847  0.04251246 -0.07679513  0.00924154 -0.09343465\n",
      " -0.00818066 -0.03848874  0.1478526  -0.02000925]...\n",
      "mitchell_marsh: [-0.16986465  0.09374627  0.07475096 -0.06596743 -0.14470837  0.11518136\n",
      " -0.01974511 -0.04579509  0.1623009  -0.05745009]...\n",
      "shreyas_iyer: [-0.1998896   0.06353078  0.01373508 -0.08508657 -0.07127576 -0.07795057\n",
      " -0.10423819 -0.05729323  0.11174344 -0.01977119]...\n",
      "gulbadin_naib: [-0.17252897  0.10151555  0.1011928  -0.03455501 -0.02204668 -0.03901882\n",
      "  0.01322512 -0.0474166   0.12697347 -0.0994478 ]...\n",
      "adil_rashid: [-0.25606138  0.11741511  0.06919749 -0.03531088 -0.08838595 -0.05518739\n",
      " -0.02498361 -0.01215728  0.21697634 -0.02503279]...\n",
      "jacques_kallis: [-0.05674905  0.04666914  0.04396917 -0.02642629 -0.08115465  0.02814811\n",
      " -0.0224756  -0.03198079  0.17328559  0.02176909]...\n",
      "suryakumar_yadav: [-0.1162236   0.17271544 -0.03922566  0.02072923 -0.01227238  0.02121776\n",
      " -0.05722504 -0.11038382  0.31034464 -0.06769803]...\n",
      "mujeeb_ur_rahman: [-0.22078891  0.09337953  0.09646837 -0.09350619 -0.08340588 -0.02261296\n",
      " -0.10261977 -0.053376    0.06085045 -0.07284846]...\n",
      "jasprit_bumrah: [-1.15732748e-01  1.08490318e-01  8.65960754e-02  1.08098609e-02\n",
      " -1.43281901e-02 -5.62662706e-02 -2.06343830e-05  2.94280732e-02\n",
      "  2.01582029e-01 -1.35631119e-02]...\n",
      "cameron_green: [-0.12911114  0.14339875  0.06574184 -0.09380537 -0.04458519  0.01370091\n",
      " -0.00781996 -0.10680494  0.0997791  -0.02343839]...\n",
      "alex_carey: [-0.12129104  0.07604144  0.02757638 -0.05515627 -0.15739968 -0.04916983\n",
      " -0.05821995 -0.02763321  0.08313733 -0.00383471]...\n",
      "matt_henry: [-0.04462982  0.09927595  0.05631596  0.0088351  -0.14195035  0.10932855\n",
      " -0.06906192 -0.15298432  0.10355475 -0.06837554]...\n",
      "trent_boult: [-0.09875403  0.11146832  0.04633892 -0.01218573 -0.17112096  0.09750386\n",
      " -0.0337724  -0.12540944  0.120048   -0.08257174]...\n",
      "sachin_tendulkar: [-0.14081885  0.15731958  0.04314139 -0.06810124 -0.08828261  0.00323099\n",
      " -0.05923    -0.01599576  0.21615636 -0.06202422]...\n",
      "kuldeep_yadav: [-0.13136463  0.1172676   0.04638686 -0.06647557 -0.16044727  0.02789739\n",
      " -0.040496   -0.08866125  0.24927258 -0.12502646]...\n",
      "david_warner: [ 0.00736629  0.1432216  -0.01871488 -0.06614377 -0.04858972 -0.01639777\n",
      " -0.07491285 -0.12019999  0.05248616  0.00070964]...\n",
      "david_miller: [-0.12326027  0.17351015  0.0785801  -0.05276083 -0.18851212 -0.04410717\n",
      " -0.04057236 -0.13949203  0.07472254 -0.01226114]...\n",
      "mitchell_santner: [-0.13171305  0.08608068  0.02398451  0.0638078  -0.12187826  0.00688654\n",
      " -0.07212342 -0.08445214  0.1016487  -0.07313149]...\n",
      "reeza_hendricks: [-0.15305635  0.14040834  0.0629063  -0.07468431 -0.01658844 -0.14290176\n",
      " -0.02253764 -0.01278715  0.19859532  0.01594422]...\n",
      "steve_smith: [-0.07399278  0.17615803  0.00324667 -0.11352161 -0.08881095 -0.03405071\n",
      "  0.00865261 -0.08777184  0.22818097 -0.05630985]...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Function to create face encodings for all players in the dataset, including augmented images\n",
    "def create_face_encodings(data_dir):\n",
    "    face_encodings = {}\n",
    "    \n",
    "    # Loop through each player directory\n",
    "    for player_name in os.listdir(data_dir):\n",
    "        player_dir = os.path.join(data_dir, player_name)\n",
    "        \n",
    "        if os.path.isdir(player_dir):  # Ensure it's a directory\n",
    "            encodings = []\n",
    "            \n",
    "            # Loop through original images in the player's directory\n",
    "            for img_name in os.listdir(player_dir):\n",
    "                img_path = os.path.join(player_dir, img_name)\n",
    "                if os.path.isfile(img_path) and not img_name.startswith('augmented'):  # Ignore augmented directory\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is not None:\n",
    "                        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "                        # Get face encodings\n",
    "                        face_encoding = face_recognition.face_encodings(rgb_img)\n",
    "                        \n",
    "                        if face_encoding:  # Check if any encoding is found\n",
    "                            encodings.append(face_encoding[0])\n",
    "            \n",
    "            # Process augmented images, if the folder exists\n",
    "            aug_dir = os.path.join(player_dir, 'augmented')\n",
    "            if os.path.exists(aug_dir):\n",
    "                for aug_img_name in os.listdir(aug_dir):\n",
    "                    aug_img_path = os.path.join(aug_dir, aug_img_name)\n",
    "                    if os.path.isfile(aug_img_path):\n",
    "                        aug_img = cv2.imread(aug_img_path)\n",
    "                        if aug_img is not None:\n",
    "                            aug_rgb_img = cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB)\n",
    "                            aug_face_encoding = face_recognition.face_encodings(aug_rgb_img)\n",
    "                            if aug_face_encoding:\n",
    "                                encodings.append(aug_face_encoding[0])\n",
    "            \n",
    "            if encodings:\n",
    "                # Average the encodings for the player to get a single representation\n",
    "                face_encodings[player_name] = np.mean(encodings, axis=0)\n",
    "\n",
    "    # Save the encodings to a file\n",
    "    with open('face_encodings_single_img_test.pkl', 'wb') as f:\n",
    "        pickle.dump(face_encodings, f)\n",
    "\n",
    "    return face_encodings\n",
    "\n",
    "# Path to the dataset directory, which includes the augmented folders\n",
    "data_dir = 'data_test'  # Change this to your dataset path\n",
    "encodings = create_face_encodings(data_dir)\n",
    "\n",
    "# Print out the encodings\n",
    "print(\"Generated Face Encodings:\")\n",
    "for name, encoding in encodings.items():\n",
    "    print(f\"{name}: {encoding[:10]}...\")  # Print first 10 values for brevity\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
