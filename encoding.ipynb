{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Face Encodings:\n",
      "marnus_labuschagne: [-0.07167649  0.05941486  0.09232408 -0.05371303 -0.13918288  0.06482795\n",
      " -0.09901533 -0.13459222  0.04080417 -0.10709846]...\n",
      "adil_rashid: [-0.25606135  0.11741509  0.06919752 -0.03531092 -0.08838598 -0.05518739\n",
      " -0.02498356 -0.01215728  0.2169763  -0.02503277]...\n",
      "glenn_maxwell: [-0.13287102  0.104762    0.04672765 -0.08413099 -0.07895122  0.06015257\n",
      " -0.023527   -0.08825604  0.18555364  0.03243889]...\n",
      "aaron_finch: [-0.21735184  0.11429384  0.01564842 -0.02436352 -0.12117404 -0.04486967\n",
      " -0.02381824 -0.14843997  0.09411033 -0.00077171]...\n",
      "harbhajan_singh: [-0.2456851   0.08384371  0.029568   -0.06538168 -0.0910781   0.0066541\n",
      " -0.02306675 -0.00900731  0.15264854 -0.11022212]...\n",
      "yuvraj_singh: [-0.20811251  0.11507615 -0.0066595  -0.00472624 -0.08054106  0.05275427\n",
      "  0.05439679  0.00714933  0.15759729  0.00208073]...\n",
      "adam_zampa: [-0.1064337   0.04487525  0.00208964 -0.12389528 -0.11446915 -0.0178614\n",
      " -0.01076034 -0.11856332  0.16099384 -0.16679779]...\n",
      "arshdeep_singh: [-0.17320597  0.07789714  0.00024613 -0.05364865  0.00934204 -0.02732287\n",
      " -0.02300621 -0.05927622  0.16748959 -0.01510212]...\n",
      "rohit_sharma: [-0.1891444   0.1169408   0.02240413 -0.06889094 -0.0081931  -0.01212927\n",
      "  0.0224236  -0.02608853  0.17662367 -0.00845375]...\n",
      "shubhman_gill: [-0.23507273  0.10616256  0.03380403 -0.07815173 -0.08625774  0.00963422\n",
      " -0.06139155 -0.05667408  0.16558991 -0.07973208]...\n",
      "aaron_hardie: [-0.1937267   0.07554424 -0.00706969 -0.11917511 -0.07016263 -0.08942833\n",
      "  0.05313002 -0.02964636  0.1595362  -0.01324776]...\n",
      "matthew_wade: [ 0.03912773  0.12277305  0.02139854 -0.07433105 -0.20682238  0.05437849\n",
      "  0.0292557  -0.03932264  0.17583133 -0.07252695]...\n",
      "ben_stokes: [-0.13714044  0.10253199  0.0436299  -0.08520892 -0.13101935  0.05662793\n",
      "  0.03727057 -0.03753904  0.0851751  -0.12965487]...\n",
      "suryakumar_yadav: [-0.11622357  0.17271549 -0.03922566  0.02072923 -0.01227233  0.02121773\n",
      " -0.05722502 -0.11038375  0.31034458 -0.06769797]...\n",
      "gus_atkinson: [-0.15953049  0.1048089   0.01040332 -0.10986863 -0.14260347 -0.00552842\n",
      " -0.0347818  -0.06755235  0.1694165  -0.1076633 ]...\n",
      "mitchell_starc: [-0.03445006  0.17351359  0.03042826 -0.11811829 -0.2028469  -0.02840498\n",
      " -0.13430949 -0.04521153  0.07944371 -0.04989216]...\n",
      "david_warner: [ 0.00736639  0.14322166 -0.01871495 -0.06614373 -0.04858973 -0.01639778\n",
      " -0.07491279 -0.12020002  0.05248625  0.00070963]...\n",
      "marcus_stoinis: [-0.049589    0.08644947  0.07029541 -0.05636308 -0.13071649  0.02821391\n",
      " -0.11674935 -0.08986413  0.19034943 -0.09967095]...\n",
      "ruturaj_gaikwad: [-0.20778832  0.01236066  0.01381018  0.01191508 -0.05414468 -0.01918101\n",
      " -0.01980278 -0.04510501  0.15014277 -0.0173986 ]...\n",
      "virat_kohli: [-0.1125199   0.08296997  0.05818203  0.01461606 -0.04671846 -0.02780109\n",
      "  0.0071479  -0.02462     0.16904233 -0.03102727]...\n",
      "yashasvi_jaiswal: [-0.14610295  0.13777913  0.01274546 -0.01363979 -0.06924485 -0.07231921\n",
      " -0.00762325 -0.11270776  0.21237482 -0.05592747]...\n",
      "virender_sehwag: [-0.15715961  0.0489927   0.03240825 -0.05154641 -0.09455286 -0.00247043\n",
      "  0.00123666 -0.12197436  0.11937072 -0.06177606]...\n",
      "chris_woakes: [-0.13098943  0.09027172  0.11401194 -0.07039902 -0.12090981  0.07260358\n",
      " -0.11753035 -0.00999261  0.19771518 -0.07742666]...\n",
      "josh_hazlewood: [-0.11571352  0.03079936 -0.00438572 -0.07399294 -0.1635554  -0.00752704\n",
      "  0.04918497 -0.10125052  0.12287139 -0.0443255 ]...\n",
      "patrick_cummins: [-0.03467824  0.10709669  0.05477162 -0.03391017 -0.16861904  0.05079257\n",
      " -0.02798777 -0.02534581  0.12776737 -0.04124274]...\n",
      "jonny_bairstow: [-0.09151688  0.08911238  0.05651811 -0.08098506 -0.08021797  0.03043859\n",
      " -0.03592656 -0.01026054  0.17596951 -0.0560687 ]...\n",
      "joe_root: [-0.19123532  0.1287383   0.06021306 -0.14771535 -0.16808942  0.02294152\n",
      " -0.04521381 -0.09367955  0.15519761 -0.11178894]...\n",
      "kuldeep_yadav: [-0.13136466  0.11726758  0.04638698 -0.06647544 -0.1604474   0.0278974\n",
      " -0.04049599 -0.08866122  0.24927267 -0.12502636]...\n",
      "kl_rahul: [-0.11407275  0.06622278  0.04604831 -0.09458372  0.03349185 -0.09173213\n",
      "  0.01056917 -0.02327281  0.13820378 -0.00082958]...\n",
      "rishabh_pant: [-0.15335152  0.07830311  0.02501365 -0.05924768 -0.12975636 -0.02052192\n",
      " -0.06501374 -0.06332489  0.10376459 -0.01415047]...\n",
      "jasprit_bumrah: [-1.15732782e-01  1.08490244e-01  8.65961239e-02  1.08098381e-02\n",
      " -1.43282232e-02 -5.62663320e-02 -2.06257682e-05  2.94280285e-02\n",
      "  2.01582007e-01 -1.35631235e-02]...\n",
      "ravichandran_ashwin: [-0.19362615  0.0283369   0.06425817 -0.05430952 -0.1173701   0.02461838\n",
      "  0.02354661 -0.07205553  0.17752795 -0.04544348]...\n",
      "mitchell_marsh: [-0.16986458  0.0937463   0.0747509  -0.06596749 -0.14470828  0.11518142\n",
      " -0.0197452  -0.04579498  0.16230091 -0.05745004]...\n",
      "harry_brook: [-0.15932636  0.07134819  0.04434934  0.01840932 -0.15194793  0.05213056\n",
      "  0.03788988 -0.1140949   0.12547831 -0.08972273]...\n",
      "ms_dhoni: [-0.09030503  0.16148672  0.05349179 -0.03233058 -0.10453583 -0.01657693\n",
      " -0.11120088 -0.1015718   0.16135044 -0.0477091 ]...\n",
      "sachin_tendulkar: [-0.14081891  0.15731961  0.04314144 -0.06810122 -0.08828255  0.00323096\n",
      " -0.05923003 -0.01599577  0.21615641 -0.06202422]...\n",
      "mohammed_shami: [-0.16035861  0.15968084  0.09442285 -0.02632659 -0.14217122 -0.02963156\n",
      " -0.10081521 -0.03967026  0.13953429 -0.0157123 ]...\n",
      "cameron_green: [-0.12911105  0.14339878  0.06574186 -0.09380534 -0.04458519  0.01370092\n",
      " -0.00781996 -0.1068049   0.09977918 -0.02343839]...\n",
      "ajinkya_rahane: [-0.0845911   0.11512629  0.04898218 -0.08790477 -0.02174402 -0.09010211\n",
      " -0.05507467 -0.01530408  0.10246249 -0.02154604]...\n",
      "travis_head: [-0.10859752  0.08510619  0.03607523 -0.05483482 -0.10359897  0.04148706\n",
      " -0.06288591 -0.0782683   0.02689771 -0.0261554 ]...\n",
      "steve_smith: [-0.07399277  0.17615807  0.00324674 -0.11352157 -0.08881088 -0.03405074\n",
      "  0.00865259 -0.0877718   0.2281809  -0.05630986]...\n",
      "bhuvneshwar_kumar: [-0.17855473  0.12675627  0.05341779 -0.05632467 -0.0930434  -0.06185364\n",
      " -0.03941815 -0.01641403  0.20616588 -0.03973643]...\n",
      "axar_patel: [-0.1251051  -0.00297561 -0.01604893 -0.08613636 -0.04014751 -0.06277867\n",
      " -0.04377794 -0.13048267  0.12020008 -0.12054016]...\n",
      "ravindra_jadeja: [-0.12613332  0.11468688  0.05488853  0.00346489 -0.12055704 -0.03653172\n",
      " -0.04521463 -0.0335374   0.14131148 -0.05024772]...\n",
      "ashton_agar: [-0.06446337  0.13345712  0.0753822  -0.02782911 -0.12364368  0.1275669\n",
      " -0.01373923  0.01749308  0.19933639 -0.07385138]...\n",
      "hardik_pandya: [-0.21928404  0.08495818  0.11501922  0.02033387 -0.10233393  0.00678766\n",
      "  0.05167045 -0.05003978  0.15901041  0.05602724]...\n",
      "jake_fraser-mcgurk: [-0.06675269  0.06117946  0.03428043 -0.07144839 -0.11207397  0.00684573\n",
      "  0.03429252 -0.08778126  0.06732936 -0.05777101]...\n",
      "shreyas_iyer: [-0.19988963  0.06353082  0.01373502 -0.0850866  -0.0712758  -0.07795051\n",
      " -0.10423826 -0.05729323  0.11174347 -0.01977122]...\n",
      "chahal_yuzvendra: [-0.16437136  0.06701055  0.10892945 -0.05380005  0.06222289 -0.01678315\n",
      " -0.01643085 -0.04134112  0.14867061 -0.05229017]...\n",
      "alex_carey: [-0.12129121  0.07604147  0.02757649 -0.0551562  -0.15739945 -0.04916983\n",
      " -0.05821994 -0.0276331   0.08313733 -0.00383467]...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Function to create face encodings for all players in the dataset, including augmented images\n",
    "def create_face_encodings(data_dir):\n",
    "    face_encodings = {}\n",
    "    \n",
    "    # Loop through each player directory\n",
    "    for player_name in os.listdir(data_dir):\n",
    "        player_dir = os.path.join(data_dir, player_name)\n",
    "        \n",
    "        if os.path.isdir(player_dir):  # Ensure it's a directory\n",
    "            encodings = []\n",
    "            \n",
    "            # Loop through original images in the player's directory\n",
    "            for img_name in os.listdir(player_dir):\n",
    "                img_path = os.path.join(player_dir, img_name)\n",
    "                if os.path.isfile(img_path) and not img_name.startswith('augmented'):  # Ignore augmented directory\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is not None:\n",
    "                        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "                        # Get face encodings\n",
    "                        face_encoding = face_recognition.face_encodings(rgb_img)\n",
    "                        \n",
    "                        if face_encoding:  # Check if any encoding is found\n",
    "                            encodings.append(face_encoding[0])\n",
    "            \n",
    "            # Process augmented images, if the folder exists\n",
    "            aug_dir = os.path.join(player_dir, 'augmented')\n",
    "            if os.path.exists(aug_dir):\n",
    "                for aug_img_name in os.listdir(aug_dir):\n",
    "                    aug_img_path = os.path.join(aug_dir, aug_img_name)\n",
    "                    if os.path.isfile(aug_img_path):\n",
    "                        aug_img = cv2.imread(aug_img_path)\n",
    "                        if aug_img is not None:\n",
    "                            aug_rgb_img = cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB)\n",
    "                            aug_face_encoding = face_recognition.face_encodings(aug_rgb_img)\n",
    "                            if aug_face_encoding:\n",
    "                                encodings.append(aug_face_encoding[0])\n",
    "            \n",
    "            if encodings:\n",
    "                # Average the encodings for the player to get a single representation\n",
    "                face_encodings[player_name] = np.mean(encodings, axis=0)\n",
    "\n",
    "    # Save the encodings to a file\n",
    "    with open('face_encodings_single_img.pkl', 'wb') as f:\n",
    "        pickle.dump(face_encodings, f)\n",
    "\n",
    "    return face_encodings\n",
    "\n",
    "# Path to the dataset directory, which includes the augmented folders\n",
    "data_dir = 'data_test'  # Change this to your dataset path\n",
    "encodings = create_face_encodings(data_dir)\n",
    "\n",
    "# Print out the encodings\n",
    "print(\"Generated Face Encodings:\")\n",
    "for name, encoding in encodings.items():\n",
    "    print(f\"{name}: {encoding[:10]}...\")  # Print first 10 values for brevity\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
